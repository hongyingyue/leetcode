{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e80e4f50",
   "metadata": {},
   "source": [
    "## Coding Question: Implement a Decision Stump\n",
    "\n",
    "A decision stump is a decision tree with a maximum depth of 1. It consists of a single split on one feature and two leaf predictions.\n",
    "\n",
    "Your task is to implement a decision stump classifier from scratch. The stump should find the best feature and threshold to split on, using classification accuracy as the split metric.\n",
    "\n",
    "### Requirements:\n",
    "\n",
    "Implement a DecisionStump class with the following methods:\n",
    "\n",
    "#### 1. fit(X, y):\n",
    "\n",
    "Input:\n",
    "\n",
    "- X: a 2D NumPy array of shape (n_samples, n_features)\n",
    "\n",
    "- y: a 1D NumPy array of shape (n_samples,), containing class labels (0 or 1).\n",
    "\n",
    "Function:\n",
    "\n",
    "- Find the best feature and threshold to split the data such that classification accuracy is maximized.\n",
    "\n",
    "- Store the chosen feature, threshold, and predictions for the left and right child.\n",
    "\n",
    "predict(X):\n",
    "\n",
    "- Input: X: a 2D NumPy array of shape (n_samples, n_features)\n",
    "\n",
    "- Output: predictions (0 or 1) for each row, based on the learned stump.\n",
    "\n",
    "#### 2. Use classification accuracy to evaluate potential splits:\n",
    "\n",
    "Accuracy\n",
    "= Number of correct predictions / Total samples​\n",
    "\n",
    "#### 3. Assume binary classification (y ∈ {0, 1})."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d228020",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "### Clarification Questions\n",
    "1. Input\n",
    "   - data type of the features: categorical or continuous\n",
    "   - How to set thresholds: for simplicity, use existing values?\n",
    "2. Output\n",
    "3. Loss function\n",
    "   - What metric to use: Gini or Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f1a4a9",
   "metadata": {},
   "source": [
    "## Find the Best Gini-Based Split for a Binary Decision Tree\n",
    "Medium\n",
    "Machine Learning\n",
    "\n",
    "Implement a function that scans every feature and threshold in a small data set, then returns the split that minimises the weighted Gini impurity. Your implementation should support binary class labels (0 or 1) and handle ties gracefully.\n",
    "\n",
    "You will write one function:\n",
    "\n",
    "find_best_split(X: np.ndarray, y: np.ndarray) -> tuple[int, float]\n",
    "- X is an n×d NumPy array of numeric features.\n",
    "- y is a length-n NumPy array of 0/1 labels.\n",
    "\n",
    "The function returns (best_feature_index, best_threshold) for the split with the lowest weighted Gini impurity.\n",
    "If several splits share the same impurity, return the first that you encounter while scanning features and thresholds.\n",
    "\n",
    "Example:\n",
    "\n",
    "Input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "095a92bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "def gini(y_subset: np.ndarray) -> float:\n",
    "    if y_subset.size == 0:\n",
    "        return 0.0\n",
    "    p = y_subset.mean()\n",
    "    return 1.0 - (p ** 2 + (1-p) ** 2)\n",
    "\n",
    "def find_best_split(X: np.ndarray, y: np.ndarray) -> Tuple[int, float]:\n",
    "    n_samples, n_features = X.shape\n",
    "    gn = float('inf')\n",
    "    best_feature_index = -1\n",
    "    best_threshold = float('inf')\n",
    "    \n",
    "    for i in range(n_features):\n",
    "        for val in np.unique(X[:, i]):\n",
    "            y_left = y[X[:, i] <= val, ]\n",
    "            y_right = y[X[:, i] > val, ]\n",
    "            gn_l = gini(y_left)\n",
    "            gn_r = gini(y_right)\n",
    "            weighted_gn = (len(y_left) * gn_l + len(y_right) * gn_r) / n_samples\n",
    "            if weighted_gn < gn:\n",
    "                gn = weighted_gn\n",
    "                best_feature_index = i\n",
    "                best_threshold = val\n",
    "                \n",
    "    return best_feature_index, best_threshold\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fec9084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 2.5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([[2.5],[3.5],[1.0],[4.0]])\n",
    "y = np.array([0,1,0,1])\n",
    "print(find_best_split(X, y))\n",
    "\n",
    "# Output: (0, 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0421caaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 2.25)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [2.5, 1.0],\n",
    "    [1.0, 3.5],\n",
    "    [3.0, 2.0],\n",
    "    [2.0, 2.5],\n",
    "    [0.5, 1.5]\n",
    "])\n",
    "y = np.array([1, 0, 1, 0, 0])\n",
    "\n",
    "print(find_best_split(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9881b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss: accuracy\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "def find_best_split(X: np.ndarray, y: np.ndarray) -> Tuple[int, float]:\n",
    "    n_samples, n_features = X.shape\n",
    "    accuracy = -1 # better initiation\n",
    "    best_feature_index, best_threshold = -1, float('inf')\n",
    "    \n",
    "    for fea in range(n_features):\n",
    "        # Clarify: how to determine thresholds\n",
    "        # thresholds = np.unique(X[:, fea])\n",
    "        values = np.sort(np.unique(X[:, fea]))\n",
    "        thresholds = (values[:-1] + values[1:]) / 2\n",
    "        for thresh in thresholds:\n",
    "            left_mask = X[:, fea] <= thresh\n",
    "            right_mask = ~left_mask\n",
    "            \n",
    "            if left_mask.sum() == 0 or right_mask.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            # Clarify: how to label prediction to 0/1\n",
    "            pred_left = int(y[left_mask].mean() > 0.5) # > or >= ?\n",
    "            pred_right = int(y[right_mask].mean() > 0.5)\n",
    "            y_pred = np.zeros_like(y)\n",
    "            y_pred[left_mask] = pred_left\n",
    "            y_pred[right_mask] = pred_right\n",
    "            \n",
    "            acc = sum(y_pred == y) / n_samples\n",
    "            if acc > accuracy:\n",
    "                accuracy = acc\n",
    "                best_feature_index = fea\n",
    "                best_threshold = thresh\n",
    "            \n",
    "    return best_feature_index, best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e865ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 3.0)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[2.5],[3.5],[1.0],[4.0]])\n",
    "y = np.array([0,1,0,1])\n",
    "print(find_best_split(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c7449b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
